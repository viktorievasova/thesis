\chapter*{Introduction}
Last years, many researchers have been attracted by the task of Computer Vision. 
Particularly the problem of 3D reconstruction is being investigated a lot since it has 
received attention from the public. At this moment there is a great number of 
algorithms to solve problems in this area. Most of the approaches depends on 
the kind of input that is available (a set of pictures – determining is also how many pictures are taken, 
a video stream, etc.) and also on the output that we expect.The work of many researches resulted in several online applications such as PhotoSync by Microsoft or 
Google StreetView that is used by millions of people nowadays.Meanwhile we could observe a large progress of telecommunication devices. 
In last years, for an ordinary person it became very common to own a mobile phone 
that is denoted as smartphone. Especially mobile phones with Android platform are very popular. 
A built–in camera and large amount of applications is an obviosity for such kind 
of telephone.The goal of this work is to explore conceivable ways how to connect these two 
phenomenons and to create an Android application which takes a set of pictures and 
visualises the result of the reconstruction of the depth information. Due to the 
ambiguity of solving the task, we have to be aware of the fact that it is possible,
and to a certain extent even probable, that our application will be limited to only a particular
type of scenes. 

The first part of this work analyses the problem, describes available software and gives an 
overview of programming libraries and languages that were used. 
Secondly we focus on the theoretical basics and introduced approaches connected to this topic.
The next section is denoted to implementation of our application and finally we evaluate and benchmark 
our work.
\addcontentsline{toc}{chapter}{Introduction}

