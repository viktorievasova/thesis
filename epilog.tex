\chapter*{Conclusion}
\addcontentsline{toc}{chapter}{Conclusion}

Our work gives satisfiable results on the highly textured input images.
For the testing input data, in case of a bust of Ema Destinov√° we get a 3D model shaping the head and a part of a wall in the background.
In the second case, the input images give us a result as an inclined plane in the angle of the memorial in the picture.
These results are comparable with the real appearance of the scenes.

However, while we use a sum of absolute differences to detect the initial relative position, our approach fails on the pair of images with different illumination.
Also it does not give good result on the images influenced by noise, which is very common on the images taken by mobile phones camera, 
especially when the conditions of the illumination are not ideal.


\section{Future work}
As we mentioned, the results on the pair of input images with different illumination does not give good results.
We could solve it by using other approach e.g. the mutual information.

Our implementation could be also extended to the input of $n$ photos. 
It would be necessary to find the relative position of all pairs of photos.
This does not have to be calculated explicitly, but possibly we could estimate the position of two images when having the information about their position with one other image.
Detection and matching of SURF keypoints would be applied only to the pairs with an overlap.
Most of the implemented methods were designed to be easily extended for this purpose.
