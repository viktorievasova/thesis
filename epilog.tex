\chapter*{Conclusion}
\addcontentsline{toc}{chapter}{Conclusion}

Our work gives satisfiable results for photos of highly textured objects.
For the testing input data, in the case of a bust of Ema Destinov√° we get a 3D model shaping the head and a part of a wall in the background.
In the second case, the input images give us a result as an inclined plane in the angle of the memorial in the picture.
These results are comparable with the real appearance of the scenes.

However, while we use a sum of absolute differences to detect the initial relative position, our approach fails on pairs of images with varying illumination.
Also it does not give good result on the images influenced by noise, which is quite common on the images taken by mobile phone camera, 
especially when the lightening conditions are not ideal.


\section{Future work}
As we mentioned, the results on the pair of input images with different illumination does not give good results.
We could solve it by using other approach e.g. the mutual information.

Our implementation could be also extended to the input of $n$ photos. 
It would be necessary to find the relative position of all pairs of photos.
This does not have to be calculated explicitly, but possibly we could estimate the position of two images when having the information about their position with one other image.
Detection and matching of SURF keypoints would be applied only to the pairs with an overlap.
Most of the implemented methods were designed to be easily extended for this purpose.
