\chapter{Overview}
\label{chap:overview} 

% Many years of researches resulted in several applications.
% The purpose of this section is to discuss currently available software packages that provide functionality similar to that of our application. 
% Since we do not know of any piece of software solving exactly 
In this chapter, we give an overview of software solutions providing functionality related to our area -- namely, the analysis of depth information from photos and videos. 
% Since software packages solving the very same task are almost non-existent, we take a wider approach in Section 
Section \ref{soft} discusses software packages currently available to the end-users, while Section \ref{lib} describes software libraries implementing relevant algorithms. 
Section \ref{prob} is devoted specifically to our solution. 
There, we discuss what type of input the software processes and what kind of output can the user expect as a result. 
% we give an overview of available software dealing with the analysis of depth information and 3D reconstruction. 
% In the second part of this chapter, available programming languages and libraries considered for our work, are discussed.

\section{Available software packages}
\label{soft} 

% Software: 
%   - Canoma
%   - 123D 
%   - PhotoSynth 
%   - Matchmoving software (2d3 , Adobe 

\subsection{Matchmoving software} 

% The task of reconstructing 3D information from photos or videos plays important role in several types of software packages. 
Matchmoving software in the film industry represents one of the earliest widely adopted commercial applications of algorithms extracting 3D information from 2D (video) imagery.
In such a software, accurate 3D information about the scene is only a secondary product and the user is mainly interested in obtaining information about the position and orientation the camera had at the time of capture of the individual video frames.
The knowledge of these parameters allows artists to add special effects and/or other synthetic elements to the video footage. 

Although matchmoving (also called camera tracking) can be achieved using many different techniques, the prevailing method detects easily definable elements -- such as corners -- in a frame of the video and tracks their movement on the subsequent frames. 
The camera parameters are then calculated from the 2D movement of these {\it tracks}. 
In \cv\, this approach is called \term{structure from motion}, since the structure of the scene (for example, the trajectory of the camera) is determined by the apparent movement of the tracks on the video frames.  
The 3D positions of the scene-points corresponding to the detected corners can also be calculated, giving the user a very rough point cloud reconstruction of the scene.

Examples of widely used matchmoving applications include 2d3's Boujou\footnote{\url{http://www.2d3.com}} and Autodesk Matchmover\footnote{\url{http://www.autodesk.com}}.
The opensource libmv project\footnote{\url{http://code.google.com/p/libmv/}} aims to add matchmoving capabilities to the Blender 3D modelling application\footnote{\url{http://www.blender.org}}.

\subsection{Microsoft PhotoSynth} 

Microsoft PhotoSynth, based on a research by Snavely, et al. \cite{snavely2008}, has been publicly released in 2008. 
The software solution processes a set of unorganized pictures of a single scene and subsequently generates its 3D point cloud reconstruction. 
The main purpose of the reconstruction is to allow the user to navigate between the photos in a novel way that respects the physical proximity of the cameras taking the individual photos. 
Perhaps most notably, the technology has been employed at various times by the BBC and CNN \cite{cnnsynth}. 
Recently, the possibility to generate $360^\circ$ panoramas and to upload the input photos from a Windows 8 mobile phone has been added. 

Microsoft PhotoSynth is a closed-source application with most of the computation running on Microsoft's servers. 
It extends a system called {\it Photo Tourism} developed by Snavely, Seitz and Szeliski \cite{snavely2007, snavely2006}.
To obtain accurate information about the positions of the cameras it applies the SIFT algorithm (discussed in Section \ref{sec:sift}) to detect points of interest.These are then matched across images using an implementation of an approximate nearest neighbour algorithm and filtered using the RANSAC paradigm \cite{ransac}.
The theory presented in the classical monograph \cite{multipleview} is then applied to obtain external and internal camera calibration (if there is relevant EXIF information associated with the photo, then the software uses this to obtain an initial guess of the internal camera calibration parameters).
 
% One of the first applications that used to create a 3D model from a set of pictures of an object was Photosynth, designed by Microsoft in cooperation with the University of Washington \todo{citace jak na web PhotoSynthu tak na clanky Snavellyho; odstranil bych to, ze to byla jedna z prvnich aplikaci}. 
% The algorithm is based on pattern recognition and generates a 3D model of a scene photographed object including the point cloud. 
% After releasing the application, there were available only projects generated by Microsoft or BBC and later a cooperation with NASA was started. 
% Until two years later the version for public was released so users could upload own images to create a 3D model.

% In 2007, a one year after releasing Photosynth, Google introduced Street View to extend Google Maps and Google Earth. 
% At first, this additional application provided a panoramic views of cities in the USA, but soon it expanded to other places in the world.

\subsection{Autodesk 123D}

% Autodesk, an American corporation focused on 3D design software, released modelling application Autodesk 123D recently. 
% There are several additional tools available. 
Autodesk 123D is a bundle of several applications. 
One of them is 123D Catch, which creates a 3D model from a set of photos taken from different viewpoints.
The software is compatible with other Autodesk 123D applications, making it a viable solution for 3D artists who want to include real-world objects in their scenes.
The program is available for the Windows, Mac OSX, and iOS platforms.
To achieve good results, it is necessary to follow detailed instructions when taking the photos. 
% Otherwise, the resu
% The inclusion of blurred photos or untextured surfaces typically results in a failed attempt at reconstructing the scene. 
% For creating  3D model it is necessary to follow detailed instructions how to shot the pictures. 
% In most cases the process of building model fails because of wrong set of images. 
A failed reconstruction typically occurs when the photos are blurred, do not have solid background, or in the case of insufficient amount of photos. % TODO tim solid background si nejsem jisty

% TODO zvazit, kam/jestli dat nasledujici 
% If we evaluate accessibility of the software for mobile phones, Google Street View is running on every type of mobile platform without any larger errors. 
% There is a version of Photosynth for Windows phones and iOS operating system. 
% As we already mentioned, Autodesk developed a version for iOS as well. 
% But apparently, we miss applications developed for Android platform.

\section{Available libraries}
\label{lib} 

We now briefly introduce the main \cv\ or computer graphics libraries that provide implementations of some of the algorithms necessary to build our software. % TODO tohle neni zrovna idealni veta...

% The problem considered in this work is getting an image information from a set of pictures and its processing afterwards.
% To be able to program a software dealing with a task from the area of computer vision, it is necessary to be familiar with a library that supports work with images. 
% That kind of functions offers OpenCV library. 

\subsection{OpenCV} 

OpenCV\footnote{\url{http://opencv.org}} is a cross-platform library originally developed by Intel. 
It provides an implementation of several hundreds of \cv\ related algorithms, 
including, e.g., camera calibration routines, image segmentation algorithms, clustering algorithms, and linear algebra solvers.
The library was originally written in pure C. 
However, in the recent years the development shifted towards C++. 
This led to the introduction of a new object oriented API. 

The library provides interfaces for C, C++, Python, and Java and supports the Windows, Linux, Mac OS, iOS, and Android platforms. 
The Android version of the library, called {\it OpenCV4Android}, provides an access to the OpenCV methods using JNI bindings.
The same approach has been used by the competing {\it JavaCV} library\footnote{\url{https://code.google.com/p/javacv/}}, which actually provides access to a wide range of computer graphics libraries (e.g., FFmpeg, OpenKinect, \dots). 

Let us now compare three variants of the same example code for OpenCV, OpenCV4Android and JavaCV to illustrate the difference between these interfaces.
A typical C++ code to detect strong corners on an image using the OpenCV function \stype{goodFeaturesToTrack} would be: 

\begin{lstlisting} 
std::vector<Point2f> corners; 
goodFeaturesToTrack(img, corners, maxCount, qualityLevel, minDistance, mask, blockSize, useHarrisDetector, k);
\end{lstlisting}

An OpenCV4Android version of the same code reads: 

\begin{lstlisting} 
MatOfPoint corners = new MatOfPoint();
Imgproc.goodFeaturesToTrack(img, corners, maxCount, qualityLevel, minDistance, mask, blockSize, useHarrisDetector, k);
\end{lstlisting} 

The JavaCV version of this would be: 

\begin{lstlisting} 
CvPoint2D32f corners = new CvPoint2D32f(maxCount);
int[] count = { maxCount };
cvGoodFeaturesToTrack(img, eig, temp, corners,
  count, qualityLevel, minDistance, mask,
  blockSize, useHarrisDetector);
\end{lstlisting}

Here, note that the JavaCV binding is derived from the older pure-C interface of OpenCV. 
For this reason, the function still expects the parameters \stype{eig} and \stype {temp} even though they are actually ignored by the current version of the library. 
The way in which the \stype{maxCount} parameter is passed to the function is another relict from the old versions of OpenCV, where it was necessary to pass it using a pointer to get back the length of the array \stype{corners} dynamically allocated inside the \stype{cvGoodFeaturesToTrack}.

Since OpenCV4Android is developed by the same group of developers as the original OpenCV and provides access to functions available only in newer versions of the library, we have decided to choose this version for the final version of our project. 

\subsection{OpenGL} 

OpenGL\footnote{\url{http://www.opengl.org/}} is an application programming interface for developing 2D and 3D graphics applications.
It is an open cross-platform environment providing mainly rendering and visualization functions.
OpenGL ES, a subset of OpenGL for embedded systems including mobile phones and consoles, has been released in 2012. 

% For our work is important that support for C, C++, Python and the Android platform is included in the library. 
% OpenCV4Android offers us great equipment for image processing. 

\section{Problem statement} 
\label{prob}

Our application's objective is to provide the user the posibility to create a rough 3D model of a scene pictured on a pair of photos. 
We expect that: 

\begin{itemize}
\item both photos are focused, reasonably sharp and not significantly over- or under-exposed, 
\item the viewpoints the camera had when taking the photos differ only by translation, 
\item the above-mentioned translation is not negligible -- our software certainly cannot reconstruct the depth information from a pair of photos that are identical,
\item there is some overlap between the two photos, i.e. some scene elements are visible on both photos,
\item the scene on the photos is highly textured -- for example, taking photos of historical houses would typically result in an appropriate input.
\end{itemize}

The output of the application is a visualization of a ``depth map'' showing the reconstructed depth information for the overlapping part common to both input photographs. 
The intended purpose of the reconstruction is purely for its visualization. 
However, we can forsee the extension of the software to offer additional features. 
For example, the ability to estimate relative dimensions of objects could be provided, although the accuracy of this would depend on how precisely the internal calibration of the phone's camera (most importantly, its focal length and sensor size) can be estimated. % XXX nepresunout tohle do concolusion & future work? 
















